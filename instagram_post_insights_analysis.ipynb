{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instagram Post insights analysis\n",
    "\n",
    "## This is an insight generator tool for Instagram posts\n",
    "\n",
    "1. Download your Instagram analytic data by going to your Instagram account setting then go to > privacy and security option > Data Download > Request Download.\n",
    "2. Create the folder \"assets\" in the root directory of the project.\n",
    "3. Extract the \"past_instagram_insights\" folder from this downloaded dataset in step 1 to this \"assets\" folder from step 2\n",
    "4. Copy and paste another folder \"media\" (which should be found in the downloaded dataset from step 2) to the path \"assets/past_instagram_insights/\"\n",
    "\n",
    "\n",
    "TODO:\n",
    "\n",
    "1. Analyze the comments\n",
    "2. Analyze Videos\n",
    "   1. Analyze audio from videos and Reels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the json data and convert it to a CSV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "# [convert_json_to_csv] converts the given json file to csv\n",
    "\n",
    "\n",
    "def convert_json_to_csv(parent_folder_path, file_name, top_json_key):\n",
    "\n",
    "    # Opening JSON file and loading the data\n",
    "    # into the variable data\n",
    "    with open(parent_folder_path+file_name+'.json') as json_file:\n",
    "        data = json.load(json_file)\n",
    "\n",
    "    json_data = data[top_json_key]\n",
    "\n",
    "    # now we will open a file for writing\n",
    "    data_file = open(parent_folder_path+file_name+'.csv', 'w')\n",
    "\n",
    "    # create the csv writer object\n",
    "    csv_writer = csv.writer(data_file)\n",
    "\n",
    "    # Counter variable used for writing\n",
    "    # headers to the CSV file\n",
    "    count = 0\n",
    "\n",
    "    for data in json_data:\n",
    "        if count == 0:\n",
    "            # Writing headers of CSV file\n",
    "            #header = list(data.keys())\n",
    "            csv_writer.writerow(\n",
    "                ['title', 'post_media', 'creation_timestamp', 'post_likes'])\n",
    "            count += 1\n",
    "\n",
    "        # Writing data of CSV fileu\n",
    "        # cell = [data['media_map_data']['Media Thumbnail']['title'], path_to_image_html(parent_folder_path, data['media_map_data']['Media Thumbnail']['uri']),\n",
    "        #         data['media_map_data']['Media Thumbnail']['creation_timestamp'], data['string_map_data']['Likes']['value']]\n",
    "        cell = [data['media_map_data']['Media Thumbnail']['title'], data['media_map_data']['Media Thumbnail']['uri'],\n",
    "                datetime.fromtimestamp(data['media_map_data']['Media Thumbnail']['creation_timestamp']), data['string_map_data']['Likes']['value']]\n",
    "        csv_writer.writerow(cell)\n",
    "\n",
    "    data_file.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call the convert_json_to_csv function to convert json to csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "parent_folder_path = 'assets/past_instagram_insights/'\n",
    "file_name = 'posts'\n",
    "\n",
    "# Convert the json into CSV\n",
    "convert_json_to_csv(parent_folder_path, file_name, 'organic_insights_posts')\n",
    "\n",
    "# Load this saved csv\n",
    "csv = pd.read_csv(parent_folder_path + file_name+'.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load this saved csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the saved csv\n",
    "df = pd.read_csv(parent_folder_path + file_name+'.csv', index_col=False)\n",
    "\n",
    "print('Shape: ', df.shape)\n",
    "\n",
    "# Limit the rows for testing\n",
    "# df = df.head(15)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch hashtags from the title\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = df.title\n",
    "\n",
    "all_hashtags = []\n",
    "\n",
    "# Go theough the title, and saperate out all the hashtags\n",
    "for i in range(len(titles)):\n",
    "    # Define an empty hashtag list\n",
    "    # If no hashtag is found, this empty list is returned\n",
    "    hashtags_column = []\n",
    "    title = titles[i]\n",
    "\n",
    "    if (isinstance(title, str) and '#' in title):\n",
    "        first_hashtag = title.find('#')\n",
    "        title = title[first_hashtag:]\n",
    "        hashtags_column = title.split('#')\n",
    "        hashtags_column.remove('')\n",
    "\n",
    "        # remove blank spaces\n",
    "        for j in range(len(hashtags_column)):\n",
    "            hashtags_column[j] = hashtags_column[j].replace(' ', '')\n",
    "\n",
    "    all_hashtags.append(hashtags_column)\n",
    "\n",
    "# Go through this column to get the most occuring hashtags\n",
    "hashtags_dict = {}\n",
    "for hashtag_cell in all_hashtags:\n",
    "    for single_hashtag in hashtag_cell:\n",
    "        if single_hashtag not in hashtags_dict:\n",
    "            hashtags_dict[single_hashtag] = 1\n",
    "        else:\n",
    "            hashtags_dict[single_hashtag] += 1\n",
    "\n",
    "# Rearrange the dict to have the highest occurance first\n",
    "hashtags_dict = {k: v for k, v in sorted(\n",
    "    hashtags_dict.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "# Get the first n hashtags from the most used hasttags\n",
    "max_hashtag_count = 5\n",
    "most_occuring_hashtags = list(hashtags_dict.keys())[:max_hashtag_count]\n",
    "print('Most occuring hashtags', most_occuring_hashtags)\n",
    "\n",
    "# Go through hashtags from the dataframe and set the\n",
    "hashtag_distribution = []\n",
    "hashtag_distribution\n",
    "\n",
    "# Add these hashtags as new columns\n",
    "# add appropriate values for the posts in which these hashtags occur\n",
    "for row_hashtags in all_hashtags:\n",
    "    hashtag_distribution_row = []\n",
    "    for most_occuring_hashtag in most_occuring_hashtags:\n",
    "        if most_occuring_hashtag in row_hashtags:\n",
    "            hashtag_distribution_row.append(1)\n",
    "        else:\n",
    "            hashtag_distribution_row.append(0)\n",
    "    hashtag_distribution.append(hashtag_distribution_row)\n",
    "\n",
    "# Add this occurance frequency to the dataframe\n",
    "for most_occuring_hashtag in most_occuring_hashtags:\n",
    "    df[most_occuring_hashtags] = hashtag_distribution\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saperate all the date feilds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = df.creation_timestamp\n",
    "\n",
    "weekdays = []\n",
    "times = []\n",
    "\n",
    "for i in range(len(dates)):\n",
    "    date = datetime.fromisoformat(dates[i])\n",
    "    # Add day of the week as an integer, where Monday is 0 and Sunday is 6.\n",
    "    weekdays.append(date.weekday())\n",
    "\n",
    "    # Add time as a float\n",
    "    times.append(date.time().hour + (date.time().minute / 60))\n",
    "\n",
    "df['post_weekday'] = weekdays\n",
    "df['post_time'] = times\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Dominant color from an image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from colorthief import ColorThief\n",
    "import webcolors\n",
    "\n",
    "# To find the closest colour name https://stackoverflow.com/a/9694246/6559381\n",
    "\n",
    "\n",
    "def closest_colour(requested_colour):\n",
    "    min_colours = {}\n",
    "    for key, name in webcolors.css3_hex_to_names.items():\n",
    "        r_c, g_c, b_c = webcolors.hex_to_rgb(key)\n",
    "        rd = (r_c - requested_colour[0]) ** 2\n",
    "        gd = (g_c - requested_colour[1]) ** 2\n",
    "        bd = (b_c - requested_colour[2]) ** 2\n",
    "        min_colours[(rd + gd + bd)] = name\n",
    "    return min_colours[min(min_colours.keys())]\n",
    "\n",
    "\n",
    "post_media = df.post_media\n",
    "\n",
    "dominant_colors = []\n",
    "\n",
    "for i in range(len(post_media)):\n",
    "    # Get the image from the list of images\n",
    "    image = post_media[i]\n",
    "\n",
    "    # Get the dominant color\n",
    "    print('Finding the dominant color in the image: ', i)\n",
    "    if '.jpg' in image:\n",
    "        color_thief = ColorThief(parent_folder_path+image)\n",
    "        dominant_color = color_thief.get_color(quality=1)\n",
    "        dominant_colors.append(closest_colour((dominant_color)))\n",
    "    else:\n",
    "        dominant_colors.append('video')\n",
    "\n",
    "df['post_dominant_colors'] = dominant_colors\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop unwanted columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df.__contains__('index'):\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "if df.__contains__('title'):\n",
    "    df.drop(columns=['title'], inplace=True)\n",
    "if df.__contains__('creation_timestamp'):\n",
    "    df.drop(columns=['creation_timestamp'], inplace=True)\n",
    "if df.__contains__('post_media'):\n",
    "    df.drop(columns=['post_media'], inplace=True)\n",
    "if df.__contains__('hashtags'):\n",
    "    df.drop(columns=['hashtags'], inplace=True)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save this clean Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(parent_folder_path+file_name+'_clean.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise the most liked Data\n",
    "\n",
    "From the entire dataset, show the charecteristics of the top n most liked posts\n",
    "\n",
    "we will use _sweetviz_ to visualize the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sweetviz as sv\n",
    "\n",
    "# Creates the graph of the top n (index_to_truncate_from) most liked posts\n",
    "\n",
    "\n",
    "def visualize_top_n_most(index_to_truncate_from):\n",
    "    df_report = df.sort_values(\n",
    "        by='post_likes', ascending=False).head(index_to_truncate_from)\n",
    "    sv.analyze(df_report).show_html()\n",
    "\n",
    "\n",
    "# Creates the report graph of the top 10 most liked posts\n",
    "visualize_top_n_most(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode categorical data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le_post_dominant_colors = LabelEncoder()\n",
    "df['post_dominant_colors'] = le_post_dominant_colors.fit_transform(\n",
    "    df['post_dominant_colors'])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Training data sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Let's extract features data assigning to X and labels data assigning to:\n",
    "X = pd.DataFrame(df.values, columns=df.columns)\n",
    "y = pd.DataFrame(df['post_likes'], columns=[\"post_likes\"])\n",
    "\n",
    "(X_train, X_tmp, y_train, y_tmp) = train_test_split(\n",
    "    X, y, train_size=0.7, random_state=1)\n",
    "(X_test, X_val, y_test, y_val) = train_test_split(\n",
    "    X_tmp, y_tmp, train_size=0.6, random_state=1)\n",
    "\n",
    "\n",
    "print('Training data shape: ', X_train.shape)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Testing data shape: ', X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Decision Tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from subprocess import call\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Defining and fitting a DecisionTreeClassifier instance\n",
    "tree1 = DecisionTreeClassifier()\n",
    "tree1.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate the Decision tee\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree1.score(X_val, y_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Decision tee\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree1.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a Prediction\n",
    "\n",
    "Now that we know how our decision tree works, let us make predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample_one_pred_tree1 = int(tree1.predict([[5, 5, 1, 3]]))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
